{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67cbe7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import csv\n",
    "import random\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from scipy.ndimage.measurements import label\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba402215",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "\n",
    "    def __init__(self, root_dir, split='train', output_size=(429,460)):\n",
    "        # Define attributes\n",
    "        self.output_size = output_size\n",
    "        self.root_dir = root_dir\n",
    "        self.split = split\n",
    "        \n",
    "        self.img_id = []\n",
    "        for filename in glob.glob(os.path.join(self.root_dir, self.split, '*.jpg')):\n",
    "            self.img_id.append(int(filename[6+len(split):6+len(split)+7]))\n",
    "    \n",
    "        self.images = []\n",
    "        for k in range(len(self.img_id)):\n",
    "            img_name = os.path.join(self.root_dir, self.split, str(self.img_id[k]) + \".jpg\")\n",
    "            img = np.array(Image.open(img_name).convert('RGB'))\n",
    "            img = transforms.functional.to_tensor(img)\n",
    "            img = transforms.functional.resize(img, self.output_size, interpolation=Image.BILINEAR)\n",
    "            self.images.append(img)\n",
    "            \n",
    "        # Load ground truth for 'train' and 'val' sets\n",
    "        if split != 'test':\n",
    "            self.segs = []\n",
    "            for k in range(len(self.img_id)):\n",
    "                seg_name = os.path.join(self.root_dir, self.split, str(self.img_id[k]) + \".npy\")\n",
    "                od = np.array(np.load(seg_name)).copy()\n",
    "                od = (od[:,:]==2).astype(np.float32)\n",
    "                od = torch.from_numpy(od[None,:,:])\n",
    "                od = transforms.functional.resize(od, self.output_size, interpolation=Image.NEAREST)\n",
    "                #seg = torch.cat([od, oc], dim=0)\n",
    "                self.segs.append(od) #seg\n",
    "                \n",
    "        print('Succesfully loaded {} dataset.'.format(split) + ' '*50)\n",
    "            \n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Image\n",
    "        img = self.images[idx]\n",
    "    \n",
    "        # Return only images for 'test' set\n",
    "        if self.split == 'test':\n",
    "            return img\n",
    "        \n",
    "        # Else, images and ground truth\n",
    "        else:\n",
    "            # Label\n",
    "            df = pd.read_csv(\"data/dataset_2images.csv\")\n",
    "            lab = torch.tensor(df[df.eid_broad == self.img_id[idx]].has_disease.values[0], dtype=torch.float32)\n",
    "            #lab = torch.tensor(self.index[str(idx)]['Label'], dtype=torch.float32)\n",
    "\n",
    "            # Segmentation masks\n",
    "            seg = self.segs[idx]\n",
    "\n",
    "            #Width\n",
    "            rows = (seg != 0).sum(1).float()\n",
    "            w = torch.mean(rows[50:400])\n",
    "            std = rows[50:400].std()\n",
    "            att = torch.FloatTensor([w, std])\n",
    "        \n",
    "            return img, lab, seg, att, str(self.img_id[idx]) + \".jpg\"   #self.index[str(idx)]['ImgName'] #lab, fov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf65d2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dice_coef(input, target):\n",
    "    '''\n",
    "    Compute dice score metric.\n",
    "    '''\n",
    "    batch_size = input.shape[0]\n",
    "    return sum([dice_coef_sample(input[k,:,:], target[k,:,:]) for k in range(batch_size)])/batch_size\n",
    "\n",
    "def dice_coef_sample(input, target):\n",
    "    iflat = input.contiguous().view(-1)\n",
    "    tflat = target.contiguous().view(-1)\n",
    "    intersection = (iflat * tflat).sum()\n",
    "    return (2. * intersection) / (iflat.sum() + tflat.sum())\n",
    "\n",
    "\n",
    "def width(binary_segmentation):\n",
    "    '''\n",
    "    Get the width along long axis from a binary segmentation.\n",
    "    '''\n",
    "\n",
    "    wd = np.mean(np.sum(binary_segmentation, axis=2)[:,50:400], axis=1) \n",
    "    return wd\n",
    "\n",
    "\n",
    "def compute_width_error(pred_od, gt_od):\n",
    "    '''\n",
    "    Compute width prediction error, along with predicted width and ground truth width.\n",
    "    '''\n",
    "    pred_width = width(pred_od)\n",
    "    gt_width = width(gt_od)\n",
    "    width_err = np.mean(np.abs(gt_width - pred_width))\n",
    "    return width_err, pred_width, gt_width\n",
    "\n",
    "\n",
    "def classif_eval(classif_preds, classif_gts):\n",
    "    '''\n",
    "    Compute AUC classification score.\n",
    "    '''\n",
    "    auc = roc_auc_score(classif_gts, classif_preds)\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e9a43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine_seg(pred):\n",
    "    '''\n",
    "    Only retain the biggest connected component of a segmentation map.\n",
    "    '''\n",
    "    np_pred = pred.numpy()\n",
    "        \n",
    "    largest_ccs = []\n",
    "    for i in range(np_pred.shape[0]):\n",
    "        labeled, ncomponents = label(np_pred[i,:,:])\n",
    "        bincounts = np.bincount(labeled.flat)[1:]\n",
    "        if len(bincounts) == 0:\n",
    "            largest_cc = labeled == 0\n",
    "        else:\n",
    "            largest_cc = labeled == np.argmax(bincounts)+1\n",
    "        largest_cc = torch.tensor(largest_cc, dtype=torch.float32)\n",
    "        largest_ccs.append(largest_cc)\n",
    "    largest_ccs = torch.stack(largest_ccs)\n",
    "    \n",
    "    return largest_ccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbd6e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels=3, n_classes=1):\n",
    "        super(UNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.epoch = 0\n",
    "\n",
    "        self.inc = DoubleConv(n_channels, 64)\n",
    "        self.down1 = Down(64, 128)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.down3 = Down(256, 512)\n",
    "        factor = 2 \n",
    "        self.down4 = Down(512, 1024 // factor)\n",
    "        self.up1 = Up(1024, 512 // factor)\n",
    "        self.up2 = Up(512, 256 // factor)\n",
    "        self.up3 = Up(256, 128 // factor)\n",
    "        self.up4 = Up(128, 64)\n",
    "        self.output_layer = OutConv(64, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        out = self.up1(x5, x4)\n",
    "        out = self.up2(out, x3)\n",
    "        out = self.up3(out, x2)\n",
    "        out = self.up4(out, x1)\n",
    "        out = self.output_layer(out)\n",
    "        out = torch.sigmoid(out)\n",
    "        return out\n",
    "\n",
    "    \n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        # Use the normal convolutions to reduce the number of channels\n",
    "        self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
    "\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        # input is CHW\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    '''\n",
    "    Simple convolution.\n",
    "    '''\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d64a8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = 'data'\n",
    "lr = 1e-4\n",
    "batch_size = 5\n",
    "num_workers = 0\n",
    "total_epoch = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f03084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets\n",
    "train_set = Dataset(root_dir, \n",
    "                          split='train')\n",
    "val_set = Dataset(root_dir, \n",
    "                        split='val')\n",
    "test_set = Dataset(root_dir, \n",
    "                         split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca958fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloaders\n",
    "train_loader = DataLoader(train_set, \n",
    "                          batch_size=batch_size, \n",
    "                          shuffle=True, \n",
    "                          num_workers=num_workers,\n",
    "                          pin_memory=True,\n",
    "                         )\n",
    "val_loader = DataLoader(val_set, \n",
    "                        batch_size=batch_size, \n",
    "                        shuffle=False, \n",
    "                        num_workers=num_workers,\n",
    "                        pin_memory=True,\n",
    "                        )\n",
    "test_loader = DataLoader(test_set, \n",
    "                        batch_size=batch_size, \n",
    "                        shuffle=False, \n",
    "                        num_workers=num_workers,\n",
    "                        pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df187026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device\n",
    "device = torch.device(\"cuda:0\")\n",
    "#device = torch.device(\"cpu\")\n",
    "\n",
    "# Network\n",
    "model = UNet(n_channels=3, n_classes=1).to(device)\n",
    "\n",
    "# Loss\n",
    "seg_loss = torch.nn.BCELoss(reduction='mean')\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc6d66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "nb_train_batches = 3 #len(train_loader)\n",
    "nb_val_batches = 3 #len(val_loader)\n",
    "nb_iter = 0\n",
    "best_val_auc = 0.\n",
    "\n",
    "while model.epoch < total_epoch:\n",
    "    # Accumulators\n",
    "    train_widths, val_widths = [], []\n",
    "    train_classif_gts, val_classif_gts = [], []\n",
    "    train_loss, val_loss = 0., 0.\n",
    "    train_dsc_od, val_dsc_od = 0., 0.\n",
    "    train_width_error, val_width_error = 0., 0.\n",
    "    \n",
    "    ############\n",
    "    # TRAINING #\n",
    "    ############\n",
    "    model.train()\n",
    "    train_data = iter(train_loader)\n",
    "    for k in range(nb_train_batches):\n",
    "        # Loads data\n",
    "        imgs, classif_gts, seg_gts, fov_coords, names = train_data.next()\n",
    "        imgs, classif_gts, seg_gts = imgs.to(device), classif_gts.to(device), seg_gts.to(device)\n",
    "        # Forward pass\n",
    "        logits = model(imgs)\n",
    "        loss = seg_loss(logits, seg_gts)\n",
    " \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() / nb_train_batches\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # Compute segmentation metric\n",
    "            pred_od = refine_seg((logits[:,0,:,:]>=0.5).type(torch.int8).cpu()).to(device)\n",
    "            gt_od = seg_gts[:,0,:,:].type(torch.int8)\n",
    "            dsc_od = compute_dice_coef(pred_od, gt_od)\n",
    "            train_dsc_od += dsc_od.item()/nb_train_batches\n",
    "\n",
    "\n",
    "            # Compute and store widths\n",
    "            width_error, pred_width, gt_width = compute_width_error(pred_od.cpu().numpy(), gt_od.cpu().numpy())\n",
    "            train_widths += pred_width.tolist()\n",
    "            train_width_error += width_error / nb_train_batches\n",
    "            train_classif_gts += classif_gts.cpu().numpy().tolist()\n",
    "            \n",
    "        # Increase iterations\n",
    "        nb_iter += 1\n",
    "        \n",
    "        # Std out\n",
    "        print('Epoch {}, iter {}/{}, loss {:.6f}'.format(model.epoch+1, k+1, nb_train_batches, loss.item()) + ' '*20)\n",
    "        \n",
    "    # Train a logistic regression on widths\n",
    "    train_widths = np.array(train_widths).reshape(-1,1)\n",
    "    train_classif_gts = np.array(train_classif_gts)\n",
    "    clf = LogisticRegression(random_state=0, solver='lbfgs').fit(train_widths, train_classif_gts)\n",
    "    train_classif_preds = clf.predict_proba(train_widths)[:,1]\n",
    "    train_auc = classif_eval(train_classif_preds, train_classif_gts)\n",
    "    \n",
    "    ##############\n",
    "    # VALIDATION #\n",
    "    ##############\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_data = iter(val_loader)\n",
    "        for k in range(nb_val_batches):\n",
    "            # Loads data\n",
    "            imgs, classif_gts, seg_gts, fov_coords, names = val_data.next()\n",
    "            imgs, classif_gts, seg_gts = imgs.to(device), classif_gts.to(device), seg_gts.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            logits = model(imgs)\n",
    "            val_loss += seg_loss(logits, seg_gts).item() / nb_val_batches\n",
    "\n",
    "            # Std out\n",
    "            print('Validation iter {}/{}'.format(k+1, nb_val_batches) + ' '*50, \n",
    "                  end='\\r')\n",
    "            \n",
    "            # Compute segmentation metric\n",
    "            pred_od = refine_seg((logits[:,0,:,:]>=0.5).type(torch.int8).cpu()).to(device)\n",
    "            gt_od = seg_gts[:,0,:,:].type(torch.int8)\n",
    "            dsc_od = compute_dice_coef(pred_od, gt_od)\n",
    "            val_dsc_od += dsc_od.item()/nb_val_batches\n",
    "            \n",
    "            # Compute and store widths\n",
    "            width_error, pred_width, gt_width = compute_width_error(pred_od.cpu().numpy(), gt_od.cpu().numpy())\n",
    "            val_widths += pred_width.tolist()\n",
    "            val_width_error += width_error / nb_val_batches\n",
    "            val_classif_gts += classif_gts.cpu().numpy().tolist()\n",
    "            \n",
    "\n",
    "    # CVD predictions from widths\n",
    "    val_widths = np.array(val_widths).reshape(-1,1)\n",
    "    val_classif_gts = np.array(val_classif_gts)\n",
    "    val_classif_preds = clf.predict_proba(val_widths)[:,1]\n",
    "    val_auc = classif_eval(val_classif_preds, val_classif_gts)\n",
    "        \n",
    "    # Validation results\n",
    "    print('VALIDATION epoch {}'.format(model.epoch+1)+' '*50)\n",
    "    print('LOSSES: {:.4f} (train), {:.4f} (val)'.format(train_loss, val_loss))\n",
    "    print('Segmentation (Dice Score): {:.4f} (train), {:.4f} (val)'.format(train_dsc_od, val_dsc_od))\n",
    "    print('width error: {:.4f} (train), {:.4f} (val)'.format(train_width_error, val_width_error))\n",
    "    print('Classification (AUC): {:.4f} (train), {:.4f} (val)'.format(train_auc, val_auc))\n",
    "        \n",
    "    # End of epoch\n",
    "    model.epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c86aac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "val_widths = []\n",
    "val_classif_gts = []\n",
    "val_loss = 0.\n",
    "val_dsc_od = 0.\n",
    "val_dsc_oc = 0.\n",
    "val_width_error = 0.\n",
    "with torch.no_grad():\n",
    "    val_data = iter(val_loader)\n",
    "    for k in range(nb_val_batches):\n",
    "        # Loads data\n",
    "        imgs, classif_gts, seg_gts, fov_coords, names = val_data.next()\n",
    "        imgs, classif_gts, seg_gts = imgs.to(device), classif_gts.to(device), seg_gts.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        logits = model(imgs)\n",
    "        val_loss += seg_loss(logits, seg_gts).item() / nb_val_batches\n",
    "\n",
    "        # Std out\n",
    "        print('Validation iter {}/{}'.format(k+1, nb_val_batches) + ' '*50, \n",
    "              end='\\r')\n",
    "\n",
    "        # Compute segmentation metric\n",
    "        pred_od = refine_seg((logits[:,0,:,:]>=0.5).type(torch.int8).cpu()).to(device)\n",
    "        gt_od = seg_gts[:,0,:,:].type(torch.int8)\n",
    "        dsc_od = compute_dice_coef(pred_od, gt_od)\n",
    "        val_dsc_od += dsc_od.item()/nb_val_batches\n",
    "\n",
    "        # Compute and store widths\n",
    "        width_error, pred_width, gt_width = compute_width_error(pred_od.cpu().numpy(), gt_od.cpu().numpy())\n",
    "        val_widths += pred_width.tolist()\n",
    "        val_width_error += width_error / nb_val_batches\n",
    "        val_classif_gts += classif_gts.cpu().numpy().tolist()\n",
    "\n",
    "\n",
    "# CVD predictions from widths\n",
    "val_widths = np.array(val_widths).reshape(-1,1)\n",
    "val_classif_gts = np.array(val_classif_gts)\n",
    "val_classif_preds = clf.predict_proba(val_widths)[:,1]\n",
    "val_auc = classif_eval(val_classif_preds, val_classif_gts)\n",
    "\n",
    "# Validation results\n",
    "print('VALIDATION '+' '*50)\n",
    "print('LOSSES: {:.4f} (val)'.format(val_loss))\n",
    "print('OD segmentation (Dice Score): {:.4f} (val)'.format(val_dsc_od))\n",
    "print('width error: {:.4f} (val)'.format(val_width_error))\n",
    "print('Classification (AUC): {:.4f} (val)'.format(val_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316b42af",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_test_batches = len(test_loader)\n",
    "model.eval()\n",
    "test_widths = []\n",
    "with torch.no_grad():\n",
    "    test_data = iter(test_loader)\n",
    "    for k in range(nb_test_batches):\n",
    "        # Loads data\n",
    "        imgs = test_data.next()\n",
    "        imgs = imgs.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        logits = model(imgs)\n",
    "\n",
    "        # Std out\n",
    "        print('Test iter {}/{}'.format(k+1, nb_test_batches) + ' '*50, \n",
    "              end='\\r')\n",
    "            \n",
    "        # Compute segmentation\n",
    "        pred_od = refine_seg((logits[:,0,:,:]>=0.5).type(torch.int8).cpu()).to(device)\n",
    "            \n",
    "        # Compute and store widths\n",
    "        pred_width = vertical_cup_to_disc_ratio(pred_od.cpu().numpy(), pred_oc.cpu().numpy())\n",
    "        test_widths += pred_width.tolist()\n",
    "            \n",
    "\n",
    "    # CVD predictions from widths\n",
    "    test_widths = np.array(test_widths).reshape(-1,1)\n",
    "    test_classif_preds = clf.predict_proba(test_widths)[:,1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
